# Dockerfile.sagemaker-h100-fixed
FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.7.1-gpu-py312-cu128-ubuntu22.04-sagemaker-v1.0

# Set environment variables
ENV PYTHONPATH=/opt/ml/code:$PYTHONPATH
ENV CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ENV NCCL_DEBUG=INFO
ENV NCCL_TREE_THRESHOLD=0

# Install system dependencies
RUN apt-get update && apt-get install -y \
    s3fs \
    fuse \
    awscli \
    git \
    curl \
    wget \
    build-essential \
    software-properties-common \
    && rm -rf /var/lib/apt/lists/*

# Install essential Python packages first
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Install core RAPIDS packages compatible with CUDA 12.8 and Python 3.12
RUN pip install --no-cache-dir \
    cudf-cu12==24.12.* \
    dask-cudf-cu12==24.12.* \
    cupy-cuda12x \
    rmm-cu12==24.12.*

# Install Dask and distributed computing packages
RUN pip install --no-cache-dir \
    dask[complete]==2024.11.* \
    dask-cuda \
    distributed

# Install data processing packages
RUN pip install --no-cache-dir \
    fsspec[s3] \
    s3fs \
    boto3 \
    pyarrow \
    fastparquet \
    pandas \
    numpy

# Install NeMo Curator (this might need to be done separately)
RUN pip install --no-cache-dir \
    nemo-curator || \
    pip install --no-cache-dir git+https://github.com/NVIDIA/NeMo-Curator.git

# Create working directories
RUN mkdir -p /mnt/fsx /mnt/s3-data /opt/ml/processing /opt/ml/input /opt/ml/output /opt/ml/code

# Set working directory
WORKDIR /opt/ml/code

# Copy processing scripts
COPY . /opt/ml/code/

# Set permissions
RUN chmod +x /opt/ml/code/*.sh 2>/dev/null || true

# Install additional utilities if needed
RUN pip install --no-cache-dir \
    tqdm \
    rich \
    psutil \
    GPUtil

# Test CUDA availability
RUN python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA devices: {torch.cuda.device_count()}')"
